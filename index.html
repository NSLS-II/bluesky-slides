<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>BlueSky Slides</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

        <style>
        .standout { color: #42b0f4; }
        .reveal p.credit { font-size: 20px; }
        </style>

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
                <section>
                    <section>
                        <img src="assets/bluesky-logo-dark.svg" />
                    </section>
                </section>
                <section>
                    <section>
                        <h3>User Facilties Have a Data Problem</h3>
                        <h3>...and many Data Opportunities! :-D</h3>
                        <p>It starts at <span class="standout">data acquisition.</span></p>
                        <p>The solution has start there too.</p>
                    </section>
                    <section>
                        <p class="standout">What changed to make data problems harder?</p>
                        <ul>
                            <li>Sources got brighter; detectors got larger and faster: greater data <em>velocity</em> and <em>volume</em>.</li>
                            <li>This exposes the <em>variety</em> problem we
                                have at user facilties:
                                <ul>
                                    <li>large and changing collection of instruments</li>
                                    <li>wide span of data rates, structures, and access patterns</li>
                                    <li>mix of well-established data processing procedures and original, improvised techniques</li>
                                </ul>
                            </li>
                            <li>Multi-modal analysis makes this an N^2, ... problem.
                        </ul>
                    </section>
                    <section>
                        <p class="standout">What changed to make data problems easier?</p>
                    </section>
                    <section>
                        Free, open-source scientific software exploded.
                        <img src="assets/state-of-the-stack-2015.png" style="max-width: 70%; height: auto;"/>
                        <p class="credit">Figure Credit: "State of the Stack" by Jake VanderPlas, SciPy Conference 2015</p>
                    </section>
                    <section>
                        <p>HPC is becoming more accessible.</p>
                        <p>One inviting example: <a href="https://jupyter.nersc.gov">jupyter.nersc.gov</a></p>
                        <table>
                            <tr>
                                <td><img src="assets/jupyter-icon.png" style="max-width: 200px; height: auto; background-color: white;" /></td>
                                <td><img src="assets/dask-icon.png" style="max-width: 200px; height: auto; background-color: white;" /></td>
                            </tr>
                        </table>
                        <ul>
                            <li>Jupyter as a familiar, user-friendly portal</li>
                            <li>Dask for familiar numpy/pandas idioms distributed over many nodes</li>
                        </ul>
                    </section>
                    <section>
                        Lately it's become more practical to work openly and collaboratively....
                        <ul>
                            <li>across instuments within a facility</li>
                            <li>between facilities</li>
                            <li>with outside communities with similar data problems (e.g. climate science)</li>
                        </ul>
                        <img src="assets/gh-screenshot.png" style="width: 100%; "/>
                    </section>
                    <section>
                        <p>...which is not a <em>new</em> idea, but ease-of-use matters.</p>
                            <img src="assets/open-source-open-science-at-bnl.png" sytle="width: 100%; height: auto;" />
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Status Quo:<br />Data and Metadata are Scattered</h3>
                        <ul>
                            <li>Some critical context is only in people's heads</li>
                            <li>Many file formats (tif, cbf, Nexus, other HDF5, proprietary, ...)</li>
                            <li><code>meta_data_in_37K_fname_005_NaCl_cal.tif</code></li>
                            <li>"Magic numbers" buried in analysis tools</li>
                            <li>Notes in paper notebooks</li>
                        </ul>
                    </section>
                    <section>
                        <p class="standout">What's the problem?</p>
                        <ul>
                            <li>Not machine-readable or searchable</li>
                            <li>Relationship between any two pieces of data unclear</li>
                            <li>Inhibits multi-modal work</li>
                            <li>Inhibits code reuse</li>
                            <li>Not streaming friendly</li>
                        </ul>
                    </section>
                    <section>
                        <p>The data-management equivalent of reaching through a cage to access the hutch....</p>
                        <img src="assets/george-brown-ssrl-1979.jpg" style="height: 200px; width: auto;" />
                        <p class="credit"><em>SSRL, 1979. George Brown reaching through a caged hutch door. H/T Ron Pindak. </em></p>
                        <p>It's a good start, but it doesn't scale.</p>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>What do we need to systematically track?</h3>
                    </section>
                    <section>
                        <p>Experimental Data</p>
                        <ul>
                            <li class="fragment">Analysis needs more than "primary" data stream</li>
                            <li class="fragment">Timestamps</li>
                            <li class="fragment">Secondary measurements</li>
                            <li class="fragment">"Fixed" experimental values</li>
                            <li class="fragment">Calibration / beam-line conguration data</li>
                            <li class="fragment">Hardware settings</li>
                            <li class="fragment">Hardware diagnostics</li>
                            <li class="fragment">Physical details of the hardware</li>
                        </ul>
                    </section>
                    <section>
                        <p>Sample Data</p>
                        <ul>
                            <li class="fragment">What is the sample?</li>
                            <li class="fragment">What is the contrast mechanism?</li>
                            <li class="fragment">Why are we looking at it?</li>
                            <li class="fragment">How was it prepared?</li>
                        </ul>
                    </section>
                    <section>
                        <p>Bureaucratic & Management Information
                        <ul>
                            <li class="fragment">Where is the data and how to get it?</li>
                            <li class="fragment">Who took the data?</li>
                            <li class="fragment">Who owns or can access the data?</li>
                            <li class="fragment">How long will we keep the data?</li>
                        </ul>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Design Goals</h3>
                        <ul>
                            <li class="fragment">Generic across science domains</li>
                            <li class="fragment">Lightweight</li>
                            <li class="fragment">Put metadata in a predictable place</li>
                            <li class="fragment">Handle asynchronous data streams</li>
                            <li class="fragment">Support muti-modal</li>
                            <li class="fragment">Simultaneous, cross-beamline, cross-facility</li>
                            <li class="fragment">Support streaming</li>
                            <li class="fragment">Cloud friendly</li>
                        </ul>
                    </section>
                    <section>
                        We want "streaming-first" tooling.
                        <ul>
                            <li>Live visualization</li>
                            <li>Live data reduction and "first pass" analysis</li>
                            <li>Adaptive experiment logic</li>
                        </ul>
                        <table>
                            <tr>
                                <td><img src="assets/tomopy-demo.gif" style="max-width: 250px; height: auto; background-color: white;" /></td>
                            </tr>
                        </table>
                        <table>
                            <tr>
                                <td><img src="assets/adaptive-scan-demo.gif" style="max-width: 250px; height: auto; background-color: white;" /></td>
                                <td><img src="assets/livefit-demo.gif" style="max-width: 250px; height: auto; background-color: white;" /></td>
                            </tr>
                        </table>
                    </section>
                </section>
                <section>
                    <section>
                        Architecture
                        <img src="assets/collection-overview.svg" style="background: white;" />
                    </section>
                    <section>
                        <p>Layered design of Python libraries that are:</p>
                        <ul>
                            <li>co-developed and compatible...</li>
                            <li>...but individually usable and useful</li>
                            <li>with well-defined programmatic interfaces</li>
                        </ul>
                        <p><em>Looking at each component, from the bottom up....</em></p>
                    </section>
                    <section>
                        Device Drivers and Underlying Control Layer(s)

                        <p>You might have a pile of hardware that communicates over one or more of:</p>
                        <ul>
                            <li>
                                <img src="assets/epics-logo.png" style="background: white; max-height: 200px; float: right;"/>
                                Experimental Physics and Industrial Control System (EPICS)
                            </li>
                            <li>LabView</li>
                            <li>Some other standard</li>
                            <li>Some vendor-specific, one-off serial or socket protocol</li>
                        </ul>
                    </section>
                    <section>
                        Ophyd abstracts over the specific control layer.
                        <img src="assets/collection-overview.svg" style="background: white;" />
                    </section>
                    <section>
                        <p>Ophyd: a hardware abstraction layer</p>
                        <ul>
                            <li>Put the control layer behind a <strong>high-level interface</strong> with methods like <code>trigger()</code>, <code>read()</code>, and <code>set(...)</code>.</li>
                            <li><strong>Group</strong> individual signals into logical "Devices" to be configured and used as one unit.</li>
                            <li>Assign signals and devices <strong>human-friendly names</strong> that propagate into metadata.</li>
                            <li><strong>Categorize</strong> signals by "kind" (primary reading, configuration, engineering/debugging).</li>
                        </ul>
                    </section>
                    <section>
                        <p>Example</p>
                        <p>Suppose I want to control two new "frobulators". This ophyd code configures them for integration with bluesky.</p>
                        <pre><code>from ophyd import Device, Signal, Component

class Frobulator(Device):
    intensity = Component(Signal, ...) 
    x = Component(Signal, ...)
    y = Component(Signal, ...)
    exposure_time = Component(Signal, ..., kind='config')
    sensor_temp = Component(Signal, ..., kind='omit')

frobulator1 = Frobulator(...)
frobulator2 = Frobulator(...)</code></pre>
                    </section>
                    <section>
                        Bluesky abstracts over hardware: a motor and temperature controller are both "things you can set".
                        <img src="assets/collection-overview.svg" style="background: white;" />
                    </section>
                    <section>
                        <p>BlueSky: an experiment specification and orchetsration engine</p>
                        <ul>
                            <li>Specify the logic of an experiment at a high level (e.g. <code>scan</code>). Employ low-level detail/control (e.g. <code>trigger</code>) only when you need it.</li>
                            <li>First-class support for <strong>adaptive feedback</strong> between analysis and acquisition.</li>
                            <li>Data is emitted in a <strong>streaming</strong> fashion in standard Python data structures.</li>
                            <li>Pause/resume, robust error handling, and rich metadata capture are built in.</li>
                        </ul>
                    </section>
                    <section>
                        The data/metadata emitted by BlueSky is persisted on disk in DataBroker.
                        <img src="assets/collection-overview.svg" style="background: white;" />
                    </section>
                    <section>
                        <p>DataBroker: rich search and access to saved data</p>
                        <ul>
                            <li>An API on top of a database (e.g. MongoDB)</li>
                            <li>Search on arbitrary user-provided or automatically-captured metadata.</li>
                            <li>Streaming-friendly (lazy)</li>
                            <li>Exactly the same layout originally emitted by bluesky, so consumer code does not distinguish between "online" and saved data</li>
                        </ul>
                    </section>
                    <section>
                        <p>Key Goal of DataBroker: Keep I/O Concerns Separate!</p>
                        <ul>
                            <li>The system is <strong>unopinionated about data formats</strong>.</li>
                            <li>Any file I/O happens transparently: the <strong>user never sees files</strong>, just gets data in memory (e.g. a numpy array).</li>
                            <li>Your detector writes in a special format? Register a custom reader at runtime.</li>
                            <li><strong>Import and exporters</strong> for some common file formats are built in. More are on the way....</li>
                        </ul>
                    </section>
                </section>
                <section>
                    <section>
                        <p>Because the data is emitted from bluesky as standard Python types, it is easy to leverage the Python ecosystem for online...</p>
                        <ul>
                            <li>visualization</li>
                            <li>reduction or compression</li>
                            <li>analysis</li>
                            <li>network transport (e.g. to HPC)</li>
                            <li>file export</li>
                        </ul>
                    </section>
                    <section>
                        TODO: Add GIFs of demos.
                    </section>
                </section>
                <section>
                    <section>
                        <p>What about large arrays, like images?</p>
                    </section>
                </section>
                <section>
                    <section>
                        <p>The Parable of Bluesky's Event Model</p>
                    </section>
                </section>
                <section>
                    <section>
                        <p>Ophyd's Verbs</p>
                    </section>
                </section>
                <section>
                    <section>
                        <p>The Parable of Bluesky's Event Model</p>
                    </section>
                </section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
